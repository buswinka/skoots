{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "```{eval-rst}\n",
    ".. role:: nge-yellow\n",
    "```\n",
    "{nge-yellow}`Detailed Training Protocol`\n",
    "==================================="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " The training process is typically invoked via the command line interface via the ```skoots-train``` command. This calls into the main function in file ```skoots.train.__main__.py```. This function parses all command line arguments, loads the config file and model, initializes pytorch DataDistributedParallel, and finally calls the ```train()``` function from ```skoots.train.engine.py```. To understand how we train SKOOTS, we will go that function in detail.  Throughout the training script, you will see references to a variable ```cfg``` which stores the users configuration data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "We must first import each package necessary for training. SKOOTS tries to take a functional approach at training. It not exactly in line with functional programing best practices, but avoids you from going into a hell of inheritance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from functools import partial\n",
    "from statistics import mean\n",
    "from typing import Callable, Union, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.optim.swa_utils\n",
    "from torch import Tensor\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "import skoots.train.loss\n",
    "from skoots.lib.embedding_to_prob import baked_embed_to_prob\n",
    "from skoots.lib.vector_to_embedding import vector_to_embedding\n",
    "from skoots.train.dataloader import dataset, MultiDataset, skeleton_colate\n",
    "from skoots.train.merged_transform import (\n",
    "    transform_from_cfg,\n",
    "    background_transform_from_cfg,\n",
    ")\n",
    "from skoots.train.setup import setup_process\n",
    "from skoots.train.sigma import Sigma, init_sigma\n",
    "from skoots.train.utils import write_progress"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup DataDistributedParallel\n",
    "We need to define 3 mandatory inputs: ```rank```, ```port```, and ```world_size```. Starting in reverse, ```world_size``` is the total number of devices to run distributed training on. If you have two GPU's in one machine, then your world size would be 2. ```port``` is the port of a local web server by which to run distributed training. ```rank``` is the process number. So for a ```world_size``` of 2, we would get two process, one where ```rank=0``` and one with ```rank=1```. World size is handled by the configuration file with ```cfg.SYSTEM.NUM_GPUS```. This function should be called through pytorch multiprocessing. See ```skoots.train.__main__.py```."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Invoked from skoots.train.__main__.py\n",
    "def train(rank: str,\n",
    "          port: str,\n",
    "          world_size: int,\n",
    "          base_model: nn.Module,\n",
    "          cfg: CfgNode\n",
    "          ) -> None:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From here we set up required processes for torch DistributedDataParallel as well as compile the model using torch inductor (if available). This lets us use multiple GPU's for training, as well as just-in-time compiled Cuda kernels for accelerated training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    setup_process(rank, world_size, port, backend=\"nccl\")\n",
    "    device = f\"cuda:{rank}\"\n",
    "\n",
    "    base_model = base_model.to(device)\n",
    "    base_model = torch.nn.parallel.DistributedDataParallel(base_model)\n",
    "\n",
    "    if int(rank) == 0:\n",
    "        print(cfg)\n",
    "\n",
    "    if int(torch.__version__[0]) >= 2:\n",
    "        print(\"Comiled with Inductor\")\n",
    "        model = torch.compile(base_model)\n",
    "    else:\n",
    "        model = torch.jit.script(base_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Augmentation\n",
    "Data augmentation parameters are set by the configuration file and executed as a single function from ```skoots.train.merged_transform.py```. This is to reduce the overhead of chaining multiple augmentation classes together, which some augmentation libraries like to do. There is a seperate set of transformations for background data, as this does not need to process masks or skeletons."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    augmentations: Callable[[Dict[str, Tensor]], Dict[str, Tensor]] = partial(\n",
    "        transform_from_cfg, cfg=cfg, device=device\n",
    "    )\n",
    "    background_agumentations: Callable[\n",
    "        [Dict[str, Tensor]], Dict[str, Tensor]\n",
    "    ] = partial(background_transform_from_cfg, cfg=cfg, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function is takes in a ```data_dict```, which is simply a python dictionary which contains the image, masks, and skeletons. Next, we load our data using the ```dataset``` class from ```skoots.train.dataloader.py```. This dataset class looks for multiple sets of three files in a single of folder with a common prefix and the extensions: ```*.tif```(the image), ```*.label.tif``` (the masks), and ```*.skeletons.trch``` (the precomputed skeletons). Training data often consists of one, really large file, too large to fit in a neural network. Therefore, the notion of an epoch doesn't make sense. Instead, SKOOTS defines an epoch as a set number of samples from each image in a dataset. This might change for different images, (you dont want to sample a small image 30 times), and therefore SKOOTS enables the user to split their datasets up in multiple folders, and define a sample rate for each.\n",
    "This is set in the config by specifying a list of potential data locations: ```_C.TRAIN.TRAIN_DATA_DIR = [data_loc_1, data_loc_2, ...]```. For each data location, we let the user define the number of samples which defines an epoch. This is reflected in code here:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    _datasets = []  # store multiple datasets\n",
    "    for path, N in zip(cfg.TRAIN.TRAIN_DATA_DIR, cfg.TRAIN.TRAIN_SAMPLE_PER_IMAGE):\n",
    "        _device = device if cfg.TRAIN.STORE_DATA_ON_GPU else \"cpu\"\n",
    "        _datasets.append(\n",
    "            dataset(\n",
    "                path=path,                  # where is our data\n",
    "                transforms=augmentations,   # augmentation function\n",
    "                sample_per_image=N,         # how many times do we sample each image?\n",
    "                device=device,              # what devive (cpu or gpu) should the data go to\n",
    "                pad_size=10,                # zero padding added to each image\n",
    "            )\n",
    "            .pin_memory()                   # pins the memory in ram for faster access\n",
    "            .to(_device)                    # if your dataset is small, or GPU is LARGE, all of the data can live on the GPU for faster access\n",
    "        )\n",
    "\n",
    "    merged_train = MultiDataset(*_datasets) # helper class which lets us access all datasets in one object\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(merged_train)\n",
    "    _n_workers = 0  # if _device != 'cpu' else 2\n",
    "\n",
    "    # put this in a pytorch dataloader for automatic batching and sampling\n",
    "    dataloader = DataLoader(\n",
    "        merged_train,\n",
    "        num_workers=_n_workers,\n",
    "        batch_size=cfg.TRAIN.TRAIN_BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=skeleton_colate,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We do the same for validation and background datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    for path, N in zip(\n",
    "        cfg.TRAIN.BACKGROUND_DATA_DIR, cfg.TRAIN.BACKGROUND_SAMPLE_PER_IMAGE\n",
    "    ):\n",
    "        _device = device if cfg.TRAIN.STORE_DATA_ON_GPU else \"cpu\"\n",
    "        _datasets.append(\n",
    "            dataset(\n",
    "                path=path,\n",
    "                transforms=background_agumentations,\n",
    "                sample_per_image=N,\n",
    "                device=device,\n",
    "                pad_size=100,\n",
    "            )\n",
    "            .pin_memory()\n",
    "            .to(_device)\n",
    "        )\n",
    "\n",
    "    merged_train = MultiDataset(*_datasets)\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(merged_train)\n",
    "    _n_workers = 0  # if _device != 'cpu' else 2\n",
    "    dataloader = DataLoader(\n",
    "        merged_train,\n",
    "        num_workers=_n_workers,\n",
    "        batch_size=cfg.TRAIN.TRAIN_BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=skeleton_colate,\n",
    "    )\n",
    "\n",
    "    # Validation Dataset\n",
    "    _datasets = []\n",
    "    for path, N in zip(\n",
    "        cfg.TRAIN.VALIDATION_DATA_DIR, cfg.TRAIN.VALIDATION_SAMPLE_PER_IMAGE\n",
    "    ):\n",
    "        _device = device if cfg.TRAIN.STORE_DATA_ON_GPU else \"cpu\"\n",
    "        _datasets.append(\n",
    "            dataset(\n",
    "                path=path,\n",
    "                transforms=augmentations,\n",
    "                sample_per_image=N,\n",
    "                device=device,\n",
    "                pad_size=10,\n",
    "            )\n",
    "            .pin_memory()\n",
    "            .to(_device)\n",
    "        )\n",
    "\n",
    "    merged_validation = MultiDataset(*_datasets)\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(merged_validation)\n",
    "    if _datasets or cfg.TRAIN.VALIDATION_BATCH_SIZE >= 1:\n",
    "        _n_workers = 0  # if _device != 'cpu' else 2\n",
    "        valdiation_dataloader = DataLoader(\n",
    "            merged_validation,\n",
    "            num_workers=_n_workers,\n",
    "            batch_size=cfg.TRAIN.VALIDATION_BATCH_SIZE,\n",
    "            sampler=test_sampler,\n",
    "            collate_fn=skeleton_colate,\n",
    "        )\n",
    "\n",
    "    else:  # we might not want to run validation...\n",
    "        valdiation_dataloader = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizers, Schedulers, Loss\n",
    "We set optimizers, learning rate schedulers, and loss functions through the config file. The constructors for each come from a list of dictonaries at the top of ```skoots.train.engine.py```:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "    _valid_optimizers = {\n",
    "        \"adamw\": torch.optim.AdamW,\n",
    "        \"adam\": torch.optim.Adam,\n",
    "        \"sgd\": torch.optim.SGD,\n",
    "        \"adamax\": torch.optim.Adamax,\n",
    "    }\n",
    "\n",
    "    _valid_loss_functions = {\n",
    "        \"soft_cldice\": skoots.train.loss.soft_dice_cldice,\n",
    "        \"tversky\": skoots.train.loss.tversky,\n",
    "    }\n",
    "\n",
    "    _valid_lr_schedulers = {\n",
    "        \"cosine_annealing_warm_restarts\": torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Within the training script, we get the constructor for each from these valid options, and call into it with other arguments set by the config file. We can set keyword arguments and values for the loss functions via the configuration as well. This is helpful when using tversky loss with different pentalties for foreground and background."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    optimizer = _valid_optimizers[cfg.TRAIN.OPTIMIZER](\n",
    "            model.parameters(),\n",
    "            lr=cfg.TRAIN.LEARNING_RATE,\n",
    "            weight_decay=cfg.TRAIN.WEIGHT_DECAY,\n",
    "        )\n",
    "    scheduler = _valid_lr_schedulers[cfg.TRAIN.SCHEDULER](\n",
    "        optimizer, T_0=cfg.TRAIN.SCHEDULER_T0\n",
    "    )\n",
    "    scaler = GradScaler(enabled=cfg.TRAIN.MIXED_PRECISION)\n",
    "\n",
    "    swa_model = torch.optim.swa_utils.AveragedModel(model)\n",
    "    swa_start = 100\n",
    "    swa_scheduler = torch.optim.swa_utils.SWALR(optimizer, swa_lr=0.05)\n",
    "\n",
    "    _kwarg = {\n",
    "        k: v for k, v in zip(cfg.TRAIN.LOSS_EMBED_KEYWORDS, cfg.TRAIN.LOSS_EMBED_VALUES)\n",
    "    }\n",
    "    loss_embed: Callable = _valid_loss_functions[cfg.TRAIN.LOSS_EMBED](**_kwarg)\n",
    "\n",
    "    _kwarg = {\n",
    "        k: v\n",
    "        for k, v in zip(\n",
    "            cfg.TRAIN.LOSS_PROBABILITY_KEYWORDS, cfg.TRAIN.LOSS_PROBABILITY_VALUES\n",
    "        )\n",
    "    }\n",
    "    loss_prob: Callable = _valid_loss_functions[cfg.TRAIN.LOSS_PROBABILITY](**_kwarg)\n",
    "\n",
    "    _kwarg = {\n",
    "        k: v\n",
    "        for k, v in zip(\n",
    "            cfg.TRAIN.LOSS_SKELETON_KEYWORDS, cfg.TRAIN.LOSS_SKELETON_VALUES\n",
    "        )\n",
    "    }\n",
    "    loss_skele: Callable = _valid_loss_functions[cfg.TRAIN.LOSS_SKELETON](**_kwarg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sigma\n",
    "To evaluate embedding accuracy, SKOOTS defines a distance penalty variable called sigma. This is implemented in its own class: ```skoots.train.sigma.py```. The parameters for this are set in the config file, and the class is constructed with the helper function ```skoots.train.sigma.init_sigma()```This penalty decays over multiple epochs and is called like a function:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    sigma: Sigma = init_sigma(cfg, device)\n",
    "    _ = sigma(100) # whats the sigma at epoch 100?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vector Scaling\n",
    "Our model will ultimately output a set of vectors from -1 to 1. This must be scaled to fit the maximum radius of any object you wish to segment. That is set here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "    vector_scale = torch.tensor(cfg.SKOOTS.VECTOR_SCALING, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before final training we also set/initalize a couple of other things"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # these disable some torch checks but can accelerate training speed\n",
    "    torch.backends.cudnn.benchmark = cfg.TRAIN.CUDNN_BENCHMARK\n",
    "    torch.autograd.profiler.profile = cfg.TRAIN.AUTOGRAD_PROFILE\n",
    "    torch.autograd.profiler.emit_nvtx(enabled=cfg.TRAIN.AUTOGRAD_EMIT_NVTX)\n",
    "    torch.autograd.set_detect_anomaly(cfg.TRAIN.AUTOGRAD_DETECT_ANOMALY)\n",
    "\n",
    "    # we use tensorboard for logging\n",
    "    writer = SummaryWriter() if rank == 0 else None\n",
    "    if writer:\n",
    "        print(\"SUMMARY WRITER LOG DIR: \", writer.get_logdir())\n",
    "\n",
    "    # Save each loss value in a list... we disregard the first one... ;)\n",
    "    avg_epoch_loss = [9999999999.9999999999]\n",
    "    avg_epoch_embed_loss = [9999999999.9999999999]\n",
    "    avg_epoch_prob_loss = [9999999999.9999999999]\n",
    "    avg_epoch_skele_loss = [9999999999.9999999999]\n",
    "\n",
    "    avg_val_loss = [9999999999.9999999999]\n",
    "    avg_val_embed_loss = [9999999999.9999999999]\n",
    "    avg_val_prob_loss = [9999999999.9999999999]\n",
    "    avg_val_skele_loss = [9999999999.9999999999]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calling the DataLoader and a Simple Training Iteration\n",
    "The DataLoader acts like an iterable which returns 5 pieces of information: the image, the labeled mask, the skeleton dictonary, the skeleton masks, and the \"baked\" skeleton. For more reference on what these are, see the Training section. We use each of these to perform a training step. First the image is passed through the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # assume current epoch is set here:\n",
    "    current_epoch = 0\n",
    "    for images, masks, skeleton, skele_masks, baked in dataloader:\n",
    "        out: Tensor = model(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The out tensor is a 5 channel tensor which contains the semantic probability map, the embedding vectors, and the skeleton map. We can separate these here:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        probability_map: Tensor = out[:, [-1], ...]\n",
    "        vector: Tensor = out[:, 0:3:1, ...]\n",
    "        predicted_skeleton: Tensor = out[:, [-2], ...]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calculate a loss, we need a skeleton embedding. To calculate the skeleton embedding we need the vectors, vector sale, and the function ```vector_to_embedding``` from ```skoots.lib.vector_to_embedding.py```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        embedding: Tensor = vector_to_embedding(vector_scale, vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have an embedding, we need a way to calculate a loss value. We do this by generating a probability score for each pixel based on how close the embedding is from it's \"true\" destination. This true destination is its closest skeleton, and contained in the baked skeleton tensor. To calculate this probability we call the function ```baked_embed_to_prob``` from ```skoots.lib.embedding_to_prob.py```."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        out: Tensor = baked_embed_to_prob(embedding, baked, sigma(current_epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This probability map is just a tensor from 0-1. It's esentially a semantic map, and therefore we can use the tversky loss with the semantic map to generate a single loss value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        _loss_embed = loss_embed(out, masks.gt(0).float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted skeletons and probability map have targets generated by the dataloader, and therefore we simply generate a loss using a similar method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        _loss_prob = loss_prob(probability_map, masks.gt(0).float())\n",
    "        _loss_skeleton = loss_skele(\n",
    "            predicted_skeleton, skele_masks.gt(0).float()\n",
    "        )  # + skel_crossover_loss(predicted_skeleton, skele_masks.gt(0).float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we let the user define the relative weight each loss value has on the overall training and the epoch at which we should first consider. This is defined in the configuration file and represented in code here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        loss = (\n",
    "            (\n",
    "                cfg.TRAIN.LOSS_EMBED_RELATIVE_WEIGHT\n",
    "                * (1 if current_epoch > cfg.TRAIN.LOSS_EMBED_START_EPOCH else 0)\n",
    "                * _loss_embed\n",
    "            )\n",
    "            + (\n",
    "                cfg.TRAIN.LOSS_PROBABILITY_RELATIVE_WEIGHT\n",
    "                * (1 if current_epoch > cfg.TRAIN.LOSS_PROBABILITY_START_EPOCH else 0)\n",
    "                * _loss_prob\n",
    "            )\n",
    "            + (\n",
    "                cfg.TRAIN.LOSS_SKELETON_RELATIVE_WEIGHT\n",
    "                * (1 if current_epoch > cfg.TRAIN.LOSS_SKELETON_START_EPOCH else 0)\n",
    "                * _loss_skeleton\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we scale the loss (if using stochastic weight averaging) and run backpropagation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warmup\n",
    "We found that over training a randomly initialized model, helps that model learn the task on new data down the line. We can do all the steps above, but just in one dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # Warmup... Get the first from train_data\n",
    "    for images, masks, skeleton, skele_masks, baked in dataloader:\n",
    "        pass\n",
    "\n",
    "    assert images is not None, len(dataloader)\n",
    "\n",
    "    warmup_range = trange(cfg.TRAIN.N_WARMUP, desc=\"Warmup: {}\")\n",
    "    for w in warmup_range:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=cfg.TRAIN.MIXED_PRECISION):  # Saves Memory!\n",
    "            out: Tensor = model(images)\n",
    "\n",
    "            probability_map: Tensor = out[:, [-1], ...]\n",
    "            vector: Tensor = out[:, 0:3:1, ...]\n",
    "            predicted_skeleton: Tensor = out[:, [-2], ...]\n",
    "\n",
    "            embedding: Tensor = vector_to_embedding(vector_scale, vector)\n",
    "            out: Tensor = baked_embed_to_prob(embedding, baked, sigma(0))\n",
    "\n",
    "            _loss_embed = loss_embed(\n",
    "                out, masks.gt(0).float()\n",
    "            )  # out = [B, 2/3, X, Y, Z?]\n",
    "            _loss_prob = loss_prob(probability_map, masks.gt(0).float())\n",
    "            _loss_skeleton = loss_skele(\n",
    "                predicted_skeleton, skele_masks.gt(0).float()\n",
    "            )  # + skel_crossover_loss(predicted_skeleton, skele_masks.gt(0).float())\n",
    "\n",
    "            loss = (\n",
    "                (cfg.TRAIN.LOSS_EMBED_RELATIVE_WEIGHT * _loss_embed)\n",
    "                + (cfg.TRAIN.LOSS_PROBABILITY_RELATIVE_WEIGHT * _loss_prob)\n",
    "                + (cfg.TRAIN.LOSS_SKELETON_RELATIVE_WEIGHT * _loss_skeleton)\n",
    "            )\n",
    "\n",
    "            warmup_range.desc = f\"{loss.item()}\"\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\n",
    "                    f\"Found NaN value in loss.\\n\\tLoss Embed: {_loss_embed}\\n\\tLoss Probability: {_loss_prob}\"\n",
    "                )\n",
    "                print(f\"\\t{torch.any(torch.isnan(vector))}\")\n",
    "                print(f\"\\t{torch.any(torch.isnan(embedding))}\")\n",
    "                continue\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Training Loop\n",
    "We can now train our entire model. This simply takes the previous method, but applies it over multiple images in our dataset, multiple times. The only difference here is we do some logging to tensorboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Step...\n",
    "    epoch_range = (\n",
    "        trange(cfg.TRAIN.NUM_EPOCHS, desc=f\"Loss = {1.0000000}\") if rank == 0 else range(cfg.TRAIN.NUM_EPOCHS)\n",
    "    )\n",
    "    for e in epoch_range:\n",
    "        _loss, _embed, _prob, _skele = [], [], [], []\n",
    "\n",
    "        if cfg.TRAIN.DISTRIBUTED:\n",
    "            train_sampler.set_epoch(e)\n",
    "\n",
    "        for images, masks, skeleton, skele_masks, baked in dataloader:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(enabled=cfg.TRAIN.MIXED_PRECISION):  # Saves Memory!\n",
    "                out: Tensor = model(images)\n",
    "\n",
    "                probability_map: Tensor = out[:, [-1], ...]\n",
    "                vector: Tensor = out[:, 0:3:1, ...]\n",
    "                predicted_skeleton: Tensor = out[:, [-2], ...]\n",
    "\n",
    "                embedding: Tensor = vector_to_embedding(vector_scale, vector)\n",
    "                out: Tensor = baked_embed_to_prob(embedding, baked, sigma(e))\n",
    "\n",
    "                _loss_embed = loss_embed(\n",
    "                    out, masks.gt(0).float()\n",
    "                )  # out = [B, 2/3, X, Y, :w\n",
    "                # Z?]\n",
    "                _loss_prob = loss_prob(probability_map, masks.gt(0).float())\n",
    "                _loss_skeleton = loss_skele(\n",
    "                    predicted_skeleton, skele_masks.gt(0).float()\n",
    "                )  # + skel_crossover_loss(predicted_skeleton, skele_masks.gt(0).float())\n",
    "\n",
    "                # fuck this small amount of code.\n",
    "                loss = (\n",
    "                    (\n",
    "                        cfg.TRAIN.LOSS_EMBED_RELATIVE_WEIGHT\n",
    "                        * (1 if e > cfg.TRAIN.LOSS_EMBED_START_EPOCH else 0)\n",
    "                        * _loss_embed\n",
    "                    )\n",
    "                    + (\n",
    "                        cfg.TRAIN.LOSS_PROBABILITY_RELATIVE_WEIGHT\n",
    "                        * (1 if e > cfg.TRAIN.LOSS_PROBABILITY_START_EPOCH else 0)\n",
    "                        * _loss_prob\n",
    "                    )\n",
    "                    + (\n",
    "                        cfg.TRAIN.LOSS_SKELETON_RELATIVE_WEIGHT\n",
    "                        * (1 if e > cfg.TRAIN.LOSS_SKELETON_START_EPOCH else 0)\n",
    "                        * _loss_skeleton\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if torch.isnan(loss):\n",
    "                    print(\n",
    "                        f\"Found NaN value in loss.\\n\\tLoss Embed: {_loss_embed}\\n\\tLoss Probability: {_loss_prob}\"\n",
    "                    )\n",
    "                    print(f\"\\t{torch.any(torch.isnan(vector))}\")\n",
    "                    print(f\"\\t{torch.any(torch.isnan(embedding))}\")\n",
    "                    continue\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if e > swa_start:\n",
    "                swa_model.update_parameters(model)\n",
    "\n",
    "            _loss.append(loss.item())\n",
    "            _embed.append(_loss_embed.item())\n",
    "            _prob.append(_loss_prob.item())\n",
    "            _skele.append(_loss_skeleton.item())\n",
    "\n",
    "        avg_epoch_loss.append(mean(_loss))\n",
    "        avg_epoch_embed_loss.append(mean(_embed))\n",
    "        avg_epoch_prob_loss.append(mean(_prob))\n",
    "        avg_epoch_skele_loss.append(mean(_skele))\n",
    "        scheduler.step()\n",
    "\n",
    "        if writer and (rank == 0):\n",
    "            writer.add_scalar(\"lr\", scheduler.get_last_lr()[-1], e)\n",
    "            writer.add_scalar(\"Loss/train\", avg_epoch_loss[-1], e)\n",
    "            writer.add_scalar(\"Loss/embed\", avg_epoch_embed_loss[-1], e)\n",
    "            writer.add_scalar(\"Loss/prob\", avg_epoch_prob_loss[-1], e)\n",
    "            writer.add_scalar(\"Loss/skele-mask\", avg_epoch_skele_loss[-1], e)\n",
    "            write_progress(\n",
    "                writer=writer,\n",
    "                tag=\"Train\",\n",
    "                epoch=e,\n",
    "                images=images,\n",
    "                masks=masks,\n",
    "                probability_map=probability_map,\n",
    "                vector=vector,\n",
    "                out=out,\n",
    "                skeleton=skeleton,\n",
    "                predicted_skeleton=predicted_skeleton,\n",
    "                gt_skeleton=skele_masks,\n",
    "            )\n",
    "\n",
    "        # # Validation Step\n",
    "        if e % 10 == 0 and valdiation_dataloader:\n",
    "            _loss, _embed, _prob, _skele = [], [], [], []\n",
    "            for images, masks, skeleton, skele_masks, baked in valdiation_dataloader:\n",
    "                with autocast(enabled=cfg.TRAIN.MIXED_PRECISION):  # Saves Memory!\n",
    "                    with torch.no_grad():\n",
    "                        out: Tensor = model(images)\n",
    "\n",
    "                        probability_map: Tensor = out[:, [-1], ...]\n",
    "                        predicted_skeleton: Tensor = out[:, [-2], ...]\n",
    "                        vector: Tensor = out[:, 0:3:1, ...]\n",
    "\n",
    "                        embedding: Tensor = vector_to_embedding(vector_scale, vector)\n",
    "                        out: Tensor = baked_embed_to_prob(embedding, baked, sigma(e))\n",
    "\n",
    "                        _loss_embed = loss_embed(out, masks.gt(0).float())\n",
    "                        _loss_prob = loss_prob(probability_map, masks.gt(0).float())\n",
    "                        _loss_skeleton = loss_prob(\n",
    "                            predicted_skeleton, skele_masks.gt(0).float()\n",
    "                        )\n",
    "\n",
    "                        loss = (2 * _loss_embed) + (2 * _loss_prob) + _loss_skeleton\n",
    "\n",
    "                        if torch.isnan(loss):\n",
    "                            print(\n",
    "                                f\"Found NaN value in loss.\\n\\tLoss Embed: {_loss_embed}\\n\\tLoss Probability: {_loss_prob}\"\n",
    "                            )\n",
    "                            print(f\"\\t{torch.any(torch.isnan(vector))}\")\n",
    "                            print(f\"\\t{torch.any(torch.isnan(embedding))}\")\n",
    "                            continue\n",
    "\n",
    "                scaler.scale(loss)\n",
    "                _loss.append(loss.item())\n",
    "                _embed.append(_loss_embed.item())\n",
    "                _prob.append(_loss_prob.item())\n",
    "                _skele.append(_loss_skeleton.item())\n",
    "\n",
    "            avg_val_loss.append(mean(_loss))\n",
    "            avg_val_embed_loss.append(mean(_embed))\n",
    "            avg_val_prob_loss.append(mean(_prob))\n",
    "            avg_val_skele_loss.append(mean(_skele))\n",
    "\n",
    "            if writer and (rank == 0):\n",
    "                writer.add_scalar(\"Validation/train\", avg_val_loss[-1], e)\n",
    "                writer.add_scalar(\"Validation/embed\", avg_val_embed_loss[-1], e)\n",
    "                writer.add_scalar(\"Validation/prob\", avg_val_prob_loss[-1], e)\n",
    "                write_progress(\n",
    "                    writer=writer,\n",
    "                    tag=\"Validation\",\n",
    "                    epoch=e,\n",
    "                    images=images,\n",
    "                    masks=masks,\n",
    "                    probability_map=probability_map,\n",
    "                    vector=vector,\n",
    "                    out=out,\n",
    "                    skeleton=skeleton,\n",
    "                    predicted_skeleton=predicted_skeleton,\n",
    "                    gt_skeleton=skele_masks,\n",
    "                )\n",
    "\n",
    "        if rank == 0:\n",
    "            epoch_range.desc = (\n",
    "                f\"lr={scheduler.get_last_lr()[-1]:.3e}, Loss (train | val): \"\n",
    "                + f\"{avg_epoch_loss[-1]:.5f} | {avg_val_loss[-1]:.5f}\"\n",
    "            )\n",
    "\n",
    "        state_dict = (\n",
    "            model.module.state_dict()\n",
    "            if hasattr(model, \"module\")\n",
    "            else model.state_dict()\n",
    "        )\n",
    "        if e % 100 == 0:\n",
    "            torch.save(state_dict, cfg.TRAIN.SAVE_PATH + f\"/test_{e}.trch\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model\n",
    "Finally, each model trained by this script is saved as a dictionary with the configuration file ```cfg```, ```model_state_dict```, and the ```optimizer_state_dict```. It is saved to the same name as the SummaryWriter object for tensorboard, linking the two."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    if rank == 0:\n",
    "        state_dict = (\n",
    "            model.module.state_dict()\n",
    "            if hasattr(model, \"module\")\n",
    "            else model.state_dict()\n",
    "        )\n",
    "        constants = {\n",
    "            \"cfg\": cfg,\n",
    "            \"model_state_dict\": state_dict,\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"avg_epoch_loss\": avg_epoch_loss,\n",
    "            \"avg_epoch_embed_loss\": avg_epoch_embed_loss,\n",
    "            \"avg_epoch_prob_loss\": avg_epoch_prob_loss,\n",
    "            \"avg_epoch_skele_loss\": avg_epoch_skele_loss,\n",
    "            \"avg_val_loss\": avg_epoch_loss,\n",
    "            \"avg_val_embed_loss\": avg_epoch_embed_loss,\n",
    "            \"avg_val_prob_loss\": avg_epoch_prob_loss,\n",
    "            \"avg_val_skele_loss\": avg_epoch_skele_loss,\n",
    "        }\n",
    "        try:\n",
    "            torch.save(\n",
    "                constants,\n",
    "                f\"{cfg.TRAIN.SAVE_PATH}/{os.path.split(writer.log_dir)[-1]}.trch\",\n",
    "            )\n",
    "        except:\n",
    "            print(\n",
    "                f\"Could not save at: {cfg.TRAIN.SAVE_PATH}/{os.path.split(writer.log_dir)[-1]}.trch\"\n",
    "                f\"Saving at {os.getcwd()}/{os.path.split(writer.log_dir)[-1]}.trch instead\"\n",
    "            )\n",
    "\n",
    "            torch.save(\n",
    "                constants,\n",
    "                f\"{os.getcwd()}/{os.path.split(writer.log_dir)[-1]}.trch\",\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}